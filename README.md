**BERT-based text summarizers**

## Table of Contents

- [Table of Contents](#table-of-contents)
- [About the Project](#about-the-project)
- [Getting started](#getting-started)
- [Usage](#usage)
- [Roadmap](#roadmap)
- [Contributing](#contributing)
- [License](#license)
- [Contact](#contact)
- [Acknowledgements](#acknowledgements)

## About the Project

- This repository will provide various summarization models using BERT.

## Getting started

TBW

## Usage

TBW

## Roadmap

- BertSumExt

## Contributing

TBW

## License

Distributed under the MIT License. See `LICENSE` for more information.

## Contact

Keisuke Hirota - [@rad0717](https://twitter.com/rad0717) - tahiro.k.ad[at]gmail.com

Project Link: [https://github.com/k-tahiro/bert-summarizer](https://github.com/k-tahiro/bert-summarizer)

## Acknowledgements

- EMNLP 2019 paper [Text Summarization with Pretrained Encoders](https://arxiv.org/abs/1908.08345)
  - [nlpyang/PreSumm](https://github.com/nlpyang/PreSumm)
